{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3269cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read jsonl file\n",
    "import json\n",
    "\n",
    "train = []\n",
    "with open(\"train.jsonl\", \"r\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        train.append(json.loads(line))\n",
    "\n",
    "print(train[0]['question'], train[0]['points'], train[0]['article'])\n",
    "print(len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92760bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate proportion of testcases where answer can be found in the question\n",
    "total = 0\n",
    "found = 0\n",
    "for set in train:\n",
    "    total += 1\n",
    "    if set['article'].lower() in set['question'].lower():\n",
    "        found += 1\n",
    "\n",
    "print(found,total,found/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b3dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not as many as I thought, but still a significant amount\n",
    "\n",
    "# Perhaps the points are a good indicator of more trivial questions, where the answer is in the question?\n",
    "# Investigate the distribution of points\n",
    "\n",
    "from statistics import mean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trivial = []\n",
    "nontrivial = []\n",
    "\n",
    "for set in train:\n",
    "    if set['article'].lower() in set['question'].lower():\n",
    "        trivial.append(set['points'])\n",
    "    else:\n",
    "        nontrivial.append(set['points'])\n",
    "\n",
    "all = trivial + nontrivial\n",
    "\n",
    "print(mean(trivial), mean(nontrivial))\n",
    "print(mean(all))\n",
    "\n",
    "sns.displot(trivial)\n",
    "sns.displot(nontrivial)\n",
    "plt.show()\n",
    "\n",
    "# There is a strong correlation, perhaps we can bias the model towards \n",
    "# retrieving the answer from the question if the points are low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I suspect most of the answers are nouns. Let's use NLP to check this.\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "is_noun = 0\n",
    "not_noun = 0\n",
    "not_noun_examples = []\n",
    "\n",
    "docs = list(nlp.pipe([set['article'] for set in train]))\n",
    "for doc in docs:\n",
    "    if len(list(doc.noun_chunks)) >= 1:\n",
    "        is_noun += 1\n",
    "    else:\n",
    "        not_noun += 1\n",
    "        not_noun_examples.append(doc.text)\n",
    "\n",
    "print(is_noun, not_noun, is_noun/(is_noun+not_noun))\n",
    "print(not_noun_examples[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More than 85% of the articles are nouns, so we should prioritise nouns in our search.\n",
    "# Many of the articles not classified as nouns are in fact nouns, many of them being years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's process the wikipedia dataset using parquet\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10210253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "wikipedia = pq.read_table('train-00000-of-00001.parquet').to_pandas()\n",
    "wikipedia = wikipedia[:10000]\n",
    "wikipedia = wikipedia[['text', 'title']]\n",
    "print(wikipedia.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best way to tackle this problem should be to use a vector database. Let's set up milvus for this.\n",
    "# Milvus is being run in a docker container in the milvus folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to milvus server\n",
    "# Credit to this tutorial by Stephen Collins for information on setting up milvus and text embedding\n",
    "# https://dev.to/stephenc222/how-to-use-milvus-to-store-and-query-vector-embeddings-5hhl\n",
    "from pymilvus import connections\n",
    "\n",
    "def connect_to_milvus():\n",
    "    try:\n",
    "        connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "        print(\"Connected to Milvus.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to Milvus: {e}\")\n",
    "        raise\n",
    "\n",
    "connect_to_milvus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c52ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up schema and create a collection\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "\n",
    "def create_collection(name, fields, description):\n",
    "    schema = CollectionSchema(fields, description)\n",
    "    collection = Collection(name, schema, consistency_level=\"Strong\")\n",
    "    return collection\n",
    "\n",
    "def drop_collection(name):\n",
    "    collection = Collection(name)\n",
    "    collection.drop()\n",
    "    \n",
    "# Define fields for our collection\n",
    "fields = [\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=768),\n",
    "    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=500),\n",
    "]\n",
    "\n",
    "drop_collection(\"wikipedia_simple\")\n",
    "collection = create_collection(\"wikipedia_simple\", fields, \"Text embeddings of the simple wikipedia dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb65455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding_util import generate_embeddings\n",
    "# Generate embeddings for each article\n",
    "for i, doc in enumerate(wikipedia['text']):\n",
    "    embedding = generate_embeddings(doc)\n",
    "    # Write into file\n",
    "    with open(\"embeddings.txt\", \"a\", encoding='utf-8') as f:\n",
    "        f.write(f\"{embedding}\\n\")\n",
    "    print(f\"{i}/{len(wikipedia)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read embeddings\n",
    "with open(\"embeddings.txt\", \"r\", encoding='utf-8') as f:\n",
    "    embeddings = f.readlines()\n",
    "\n",
    "embeddings = [[float(value) for value in embedding[1:-2].split(\", \")] for embedding in embeddings]\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write into milvus\n",
    "entities = [\n",
    "    [str(i) for i in range(len(wikipedia))],\n",
    "    embeddings,\n",
    "    [str(title) for title in wikipedia['title']],\n",
    "]\n",
    "\n",
    "insert_result = collection.insert(entities)\n",
    "print(insert_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index for embeddings\n",
    "def create_index(collection, field_name, index_type, metric_type, params):\n",
    "    index = {\"index_type\": index_type, \"metric_type\": metric_type, \"params\": params}\n",
    "    collection.create_index(field_name, index)\n",
    "\n",
    "create_index(collection, \"embeddings\", \"IVF_FLAT\", \"L2\", {\"nlist\": 128})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca80661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_query(collection, search_vectors, search_field, search_params):\n",
    "    collection.load()\n",
    "    result = collection.search(search_vectors, search_field, search_params, limit=3, output_fields=[\"title\"])\n",
    "    return result[0][0].entity.get(\"title\")\n",
    "\n",
    "# Test search\n",
    "query = \"how do living organisms in a natural environment respond to changes in weather or climate?\"\n",
    "query_vector = generate_embeddings(query)\n",
    "search_and_query(collection, [query_vector], \"embeddings\", {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}})\n",
    "\n",
    "# Correctly returns \"Environment\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance of our model\n",
    "score = 0\n",
    "totalScore = 0\n",
    "\n",
    "for set in train[:500]:\n",
    "    query = set['question']\n",
    "    query_vector = generate_embeddings(query)\n",
    "    result = search_and_query(collection, [query_vector], \"embeddings\", {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}})\n",
    "    print(f\"result: {result}, answer: {set['article']}\")\n",
    "    if result.lower() in set['article'].lower():\n",
    "        score += set['points']\n",
    "    totalScore += set['points']\n",
    "\n",
    "print(f\"Our model scored {score}/{totalScore} points on the training set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model scored 15618/31274 points on the training set. \n",
    "# Let's see if we can improve this by weighing based on the points and whether the answer is in the question.\n",
    "\n",
    "# Add a is_in_question field to the train set\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(train)\n",
    "\n",
    "# Create the 'is_in_question' column\n",
    "df['is_in_question'] = df.apply(lambda row: row['article'].lower() in row['question'].lower(), axis=1).astype(int)\n",
    "\n",
    "X = df[['points']]\n",
    "y = df['is_in_question']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(f\"Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7aa4b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the search function to take into account the points and whether the answer is in the question\n",
    "def search_and_query(collection, search_vectors, search_field, search_params, points, question):\n",
    "    collection.load()\n",
    "    result = collection.search(search_vectors, search_field, search_params, limit=3, output_fields=[\"title\"])\n",
    "    in_question_prob = model.predict_proba([[points]])[0][1]\n",
    "\n",
    "    processed_results = [[article.entity.get(\"title\"), 1 - article.distance] for article in result[0]]\n",
    "\n",
    "    for article in processed_results:\n",
    "        if article[0].lower() in question.lower():\n",
    "            article[1] *= (1-in_question_prob)\n",
    "        else:\n",
    "            article[1] *= in_question_prob\n",
    "    \n",
    "    processed_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return processed_results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89d8c120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Environment, answer: Environment\n",
      "result: Poet, answer: Marcha Real\n",
      "result: Magnetic resonance imaging, answer: Magnetic resonance imaging\n",
      "result: Berlin, answer: Boroughs of Berlin\n",
      "result: Charles Dickens, answer: Heinrich Rudolf Hertz\n",
      "result: Korean War, answer: Korean War\n",
      "result: Oprah Winfrey, answer: Oprah Winfrey\n",
      "result: Cambridge, answer: Cambridgeshire\n",
      "result: Trailer, answer: Trailer\n",
      "result: Murcia, answer: Tucumán Province\n",
      "result: Indonesia, answer: Mount Merapi\n",
      "result: Nuclear reactor, answer: Nuclear fission\n",
      "result: Economy, answer: Economy of India\n",
      "result: Tree, answer: Nothofagus\n",
      "result: Spacecraft, answer: Alien\n",
      "result: Jane Fonda, answer: Peter Fonda\n",
      "result: James Monroe, answer: 1823\n",
      "result: Idaho, answer: Chief Joseph\n",
      "result: Somaliland, answer: Somaliland\n",
      "result: Language isolate, answer: Korean language\n",
      "result: Ludwig van Beethoven, answer: Ludwig van Beethoven\n",
      "result: Turtle, answer: Turtle\n",
      "result: Diesel engine, answer: Diesel engine\n",
      "result: 1143, answer: 1143\n",
      "result: Nauru, answer: Nauru\n",
      "result: Nobel Prize, answer: List of Nobel Prize winners in Literature\n",
      "result: ELISPOT, answer: ELISPOT\n",
      "result: Trade, answer: Transaction\n",
      "result: Pop music, answer: Musical genre\n",
      "result: Friends, answer: Levy Mwanawasa\n",
      "result: Kimono, answer: Kimono\n",
      "result: Newfoundland, answer: Newfoundland\n",
      "result: Romania, answer: Bucharest\n",
      "result: Guinea pig, answer: Guinea pig\n",
      "result: List of tallest structures in the world, answer: List of tallest structures in the world\n",
      "result: Casablanca, answer: Casablanca (movie)\n",
      "result: Helium, answer: Helium\n",
      "result: Creating, answer: Creating\n",
      "result: 1723, answer: 1788\n",
      "result: Perfect number, answer: Perfect number\n",
      "result: Sarcasm, answer: Joke\n",
      "result: Memory card, answer: Memory card\n",
      "result: Barbra Streisand, answer: Barbra Streisand\n",
      "result: Kim Jong-il, answer: Kim Jong-il\n",
      "result: Rodent, answer: Mouse\n",
      "result: Ice cream, answer: Percentage\n",
      "result: Hobart, answer: Hobart\n",
      "result: Radio, answer: Radio\n",
      "result: Aamir Khan, answer: Aamir Khan\n",
      "result: Poison, answer: Deadly nightshade\n",
      "result: List of stars, answer: List of stars with confirmed extrasolar planets\n",
      "result: Cheers, answer: Last call bell\n",
      "result: Hawaii, answer: Sanford Dole\n",
      "result: Enemy, answer: Enemy\n",
      "result: Wolfgang Amadeus Mozart, answer: Wolfgang Amadeus Mozart\n",
      "result: Cymru Premier, answer: NEWI Cefn Druids F.C.\n",
      "result: Agent, answer: Agent\n",
      "result: Abdou Diouf, answer: Abdou Diouf\n",
      "result: Green, answer: Dichlorphenolindophenol\n",
      "result: Ford Ka, answer: Ford Ka\n",
      "result: AFI's 100 Years... 100 Thrills, answer: Laura Dern\n",
      "result: Law, answer: De facto\n",
      "result: Natural number, answer: Set\n",
      "result: Readability, answer: Spache Readability Formula\n",
      "result: Suriname, answer: November\n",
      "result: Aleister Crowley, answer: Aleister Crowley\n",
      "result: Abigail Adams, answer: Abigail Adams\n",
      "result: RPG, answer: Role-playing game\n",
      "result: Winter Olympic Games, answer: Nagano, Nagano\n",
      "result: Rouen, answer: Normandy\n",
      "result: FC Bayern Munich, answer: FC Bayern Munich\n",
      "result: Slug, answer: Slug\n",
      "result: 1210s, answer: 1196\n",
      "result: Watch, answer: Watch\n",
      "result: Longbow, answer: Longbow\n",
      "result: Kent, answer: Maidstone\n",
      "result: Pixar, answer: Pixar\n",
      "result: Essex, answer: July 28\n",
      "result: Pelvis, answer: Pelvis\n",
      "result: 752, answer: 752\n",
      "result: Wyoming, answer: Brookhurst, Wyoming\n",
      "result: Slobodan Milošević, answer: Slobodan Milošević\n",
      "result: World War, answer: World War\n",
      "result: Philadelphia, answer: Boyz II Men\n",
      "result: Popocatépetl, answer: Popocatépetl\n",
      "result: South China tiger, answer: South China tiger\n",
      "result: Andromeda (mythology), answer: Churning of the Ocean\n",
      "result: Tsar, answer: September 1\n",
      "result: Geometry, answer: Geometry\n",
      "result: L, answer: French language\n",
      "result: Alabama, answer: Houston (disambiguation)\n",
      "result: Spice, answer: Spice\n",
      "result: Chlorophyll, answer: Chlorophyll\n",
      "result: Y, answer: Pig Latin\n",
      "result: Tram, answer: Tram\n",
      "result: Recorder, answer: Recorder\n",
      "result: Big Bang, answer: Big Bang\n",
      "result: Ajam, answer: Ajam\n",
      "result: Scotland, answer: Rugby World Cup\n",
      "result: Coin, answer: Penny\n",
      "result: Gas giant, answer: Water\n",
      "result: Hollyoaks, answer: NBC\n",
      "result: Potassium, answer: Potassium\n",
      "result: Afterlife, answer: Afterlife\n",
      "result: George Martin, answer: Paul Martin\n",
      "result: Vancouver, answer: Mount Garibaldi\n",
      "result: Paris, answer: Belfast\n",
      "result: Stadium, answer: Kreios\n",
      "result: Yi I, answer: 1899\n",
      "result: Hot dog, answer: Hot dog\n",
      "result: Ship, answer: Vessel\n",
      "result: American Idol, answer: Fantasia Barrino\n",
      "result: Andy Warhol, answer: Andy Warhol\n",
      "result: Idiom, answer: Idiom\n",
      "result: Aesthetics, answer: Aesthetics\n",
      "result: Robbie Williams, answer: Robin Williams\n",
      "result: Stirling, answer: Stirling\n",
      "result: Black pudding, answer: Bohemia\n",
      "result: Pete Best, answer: Black Sabbath\n",
      "result: Fairy tale, answer: Hans Christian Andersen\n",
      "result: Rabies, answer: Rabies\n",
      "result: Radium, answer: Atom\n",
      "result: Ford Motor Company, answer: Oxford\n",
      "result: Junichiro Koizumi, answer: January 8\n",
      "result: Rabbit, answer: Invasion\n",
      "result: Sappho, answer: Lesbos\n",
      "result: Wonders of the World, answer: Babylon\n",
      "result: Moonspell, answer: Moonspell\n",
      "result: Geoffrey Chaucer, answer: Geoffrey Chaucer\n",
      "result: Internet Explorer, answer: Web browser\n",
      "result: Tamil, answer: Tamil language\n",
      "result: Clint Eastwood, answer: Alfred Hitchcock\n",
      "result: Catherine of Aragon, answer: 1509\n",
      "result: Confederate States of America, answer: Confederate States of America\n",
      "result: Iranian Revolution, answer: July 17\n",
      "result: Isaac Newton, answer: 1642\n",
      "result: Kabir, answer: Kabir\n",
      "result: Transport, answer: Transport\n",
      "result: Past tense, answer: Past tense\n",
      "result: The Last Waltz, answer: The Last Waltz\n",
      "result: Argentina, answer: December 10\n",
      "result: August, answer: College\n",
      "result: Suriname, answer: Suriname\n",
      "result: Aquamarine, answer: Game designer\n",
      "result: World Wide Web, answer: World Wide Web\n",
      "result: Nepal, answer: Nepal\n",
      "result: All Quiet on the Western Front, answer: All Quiet on the Western Front\n",
      "result: Yellow, answer: Plum\n",
      "result: PH, answer: Lye\n",
      "result: Pornography, answer: Pornography\n",
      "result: South Pole, answer: Antarctica\n",
      "result: Joule, answer: Joule\n",
      "result: Philadelphia Flyers, answer: Philadelphia Flyers\n",
      "result: Mestizo, answer: Spanish\n",
      "result: Condiment, answer: Condiment\n",
      "result: Yankee Doodle Dandy, answer: Yankee Doodle Dandy\n",
      "result: Volcanism, answer: Chilcotin Group\n",
      "result: NBC, answer: Jamie Farr\n",
      "result: University of Florida, answer: University of Florida\n",
      "result: Chipmunk, answer: Chipmunk\n",
      "result: Vincent van Gogh, answer: Vincent van Gogh\n",
      "result: Man, answer: Mac\n",
      "result: Oklahoma, answer: Disney (disambiguation)\n",
      "result: Blitzkrieg, answer: Blitzkrieg\n",
      "result: Emily Carr, answer: 1871\n",
      "result: Minneapolis, answer: Minneapolis\n",
      "result: Batman, answer: Batman\n",
      "result: Eric Clapton, answer: Eric Clapton\n",
      "result: 1978, answer: Shooting star\n",
      "result: Fish and chips, answer: Fish and chips\n",
      "result: Thomas Edison, answer: Thomas Edison\n",
      "result: Hippocrates, answer: 50\n",
      "result: David Beckham, answer: October 24\n",
      "result: Brachiosaurus, answer: Brachiosaurus\n",
      "result: Robert Walpole, answer: March 16\n",
      "result: Giraffe, answer: Giraffidae\n",
      "result: Swim, answer: May 6\n",
      "result: Kolkata, answer: British Raj\n",
      "result: Aircraft, answer: Balloon\n",
      "result: Clarinet, answer: Transposing instrument\n",
      "result: IPod nano, answer: IPod nano\n",
      "result: Augustus, answer: 9\n",
      "result: A Tale of Two Cities, answer: A Tale of Two Cities\n",
      "result: Enterprise architecture, answer: Enterprise architecture\n",
      "result: Indonesia, answer: Malé\n",
      "result: Ottoman Empire, answer: 1578\n",
      "result: 1910, answer: The Phantom of the Opera\n",
      "result: E-mail, answer: E-mail\n",
      "result: Lawrence of Arabia, answer: Lawrence of Arabia\n",
      "result: Pipe, answer: Pipe\n",
      "result: List of communist parties, answer: List of communist parties\n",
      "result: Iran, answer: June 16\n",
      "result: Emphysema, answer: Emphysema\n",
      "result: Globalization, answer: Globalization\n",
      "result: Radio, answer: Radio control\n",
      "result: Michael Jackson, answer: ABC\n",
      "result: Ukraine, answer: Pforzheim\n",
      "result: Tornado, answer: Tornado\n",
      "result: Software, answer: Software\n",
      "result: Lunchbox, answer: Lunchbox\n",
      "result: Pope John XXIII, answer: 1881\n",
      "result: Engineering, answer: Engineering\n",
      "result: Jennifer Lopez, answer: Axl Rose\n",
      "result: China, answer: Eurasian people\n",
      "result: Allah, answer: Names of God in Islam\n",
      "result: Schindler's List, answer: Schindler's List\n",
      "result: Equestrianism, answer: Equestrianism\n",
      "result: Economic sector, answer: Economic sector\n",
      "result: String theory, answer: Calabi-Yau manifold\n",
      "result: Earthworm, answer: Continental shelf\n",
      "result: Lisa Kudrow, answer: Lisa Kudrow\n",
      "result: Hell, answer: Hell\n",
      "result: Bird, answer: Ornithology\n",
      "result: Brain, answer: Motion sensor\n",
      "result: Sodium, answer: Factor\n",
      "result: Grand Theft Auto, answer: Multiplayer video game\n",
      "result: Flag, answer: 1797\n",
      "result: Ton, answer: Ton\n",
      "result: List of nearest stars, answer: List of nearest stars\n",
      "result: Sonata form, answer: Sonata form\n",
      "result: Larry David, answer: Larry David\n",
      "result: Oscar Wilde, answer: Oscar Wilde\n",
      "result: Palmdale, California, answer: Palmdale, California\n",
      "result: Badrinath, answer: Badrinath\n",
      "result: Ziggy Stardust, answer: Ziggy Stardust\n",
      "result: Subatomic particle, answer: Subatomic particle\n",
      "result: Skene's gland, answer: Skene's gland\n",
      "result: William the Conqueror, answer: 1080\n",
      "result: Halo 2, answer: Halo 2\n",
      "result: Adverb, answer: Adverb\n",
      "result: Maoism, answer: 1720\n",
      "result: E Prime, answer: E Prime\n",
      "result: Anubis, answer: Anubis\n",
      "result: Canberra, answer: Canberra\n",
      "result: Acid, answer: Acid\n",
      "result: Sex Pistols, answer: Sid Vicious\n",
      "result: Sport, answer: Fishing rod\n",
      "result: Logo, answer: Crass\n",
      "result: Sky, answer: Blue\n",
      "result: Crop, answer: Farming\n",
      "result: Prime Minister of the United Kingdom, answer: 1960s\n",
      "result: Bono, answer: Larry Mullen Jr.\n",
      "result: Inflation, answer: Engelbert Dollfuss\n",
      "result: Maluku Islands, answer: Maluku Islands\n",
      "result: Number, answer: Axiom\n",
      "result: Water vapor, answer: Water vapor\n",
      "result: Hirohito, answer: 1222\n",
      "result: Mirza Ghulam Ahmad, answer: Mirza Ghulam Ahmad\n",
      "result: Receipt, answer: Receipt\n",
      "result: Television, answer: Television\n",
      "result: Stanley Cup, answer: Stanley Cup\n",
      "result: Claudio Monteverdi, answer: Daphne\n",
      "result: Pink Floyd, answer: Pink Floyd\n",
      "result: River Alt, answer: River Alt\n",
      "result: Tree, answer: Branch\n",
      "result: Kauai, answer: Kauai\n",
      "result: Bhutan, answer: Currency\n",
      "result: Groucho Marx, answer: Groucho Marx\n",
      "result: Pope, answer: 1347\n",
      "result: Cosmetics, answer: Powder\n",
      "result: Confucius, answer: 1\n",
      "result: Anonymity, answer: Pseudonym\n",
      "result: Tiger, answer: Tiger\n",
      "result: War, answer: Nineteen Eighty-Four\n",
      "result: John Heinz, answer: H. John Heinz III\n",
      "result: Cactus, answer: Cactus\n",
      "result: Def Leppard, answer: Def Leppard\n",
      "result: Paris, answer: Capital\n",
      "result: Alexander Hamilton, answer: 1804\n",
      "result: Aunt, answer: Aunt\n",
      "result: Economics, answer: Work\n",
      "result: Florida, answer: University of Florida\n",
      "result: Furniture, answer: Bench\n",
      "result: Junichiro Koizumi, answer: Democrat\n",
      "result: Hungary, answer: 1129\n",
      "result: Team, answer: Dozen\n",
      "result: Counterpoint, answer: Counterpoint\n",
      "result: Running of the Bulls, answer: Matsuo Basho\n",
      "result: Martin Luther, answer: Martin Luther\n",
      "result: Voodoo, answer: Voodoo\n",
      "result: Bee Gees, answer: Motown\n",
      "result: Number, answer: Mean\n",
      "result: Salzgitter, answer: Salzgitter\n",
      "result: The Screwtape Letters, answer: 1947\n",
      "result: 1500s, answer: March 9\n",
      "result: Native American, answer: Michigan\n",
      "result: The Tempest, answer: The Tempest\n",
      "result: Learning disability, answer: Learning disability\n",
      "result: Ayya Vaikundar, answer: Aarre Merikanto\n",
      "result: 1942, answer: 1940s\n",
      "result: Pollution, answer: Pollution\n",
      "result: Los Angeles Galaxy, answer: Sporting Kansas City\n",
      "result: American Sign Language, answer: American Sign Language\n",
      "result: Istanbul, answer: Istanbul\n",
      "result: Nitrogen, answer: Flatulence\n",
      "result: Restaurant, answer: Restaurant\n",
      "result: Ronald Reagan, answer: Tampico\n",
      "result: Phases of the Moon, answer: Phases of the Moon\n",
      "result: God, answer: God\n",
      "result: Ping Pong, answer: Ping Pong\n",
      "result: Machine gun, answer: Machine gun\n",
      "result: Chimbote, answer: Chimbote\n",
      "result: Ankara, answer: Ankara\n",
      "result: Meryl Streep, answer: 1972\n",
      "result: Edith Massey, answer: Edith Massey\n",
      "result: Lisgar Collegiate Institute, answer: Lisgar Collegiate Institute\n",
      "result: Olivine, answer: List of rock types\n",
      "result: Fish, answer: Cod\n",
      "result: Dominica, answer: Dominica\n",
      "result: Carbon, answer: C\n",
      "result: Raptor, answer: Boeing B-17 Flying Fortress\n",
      "result: King Arthur, answer: Tintagel Castle\n",
      "result: Ethernet, answer: Ethernet\n",
      "result: Jeb Bush, answer: Jeb Bush\n",
      "result: Venice, answer: Venetian\n",
      "result: Exponentiation, answer: Exponentiation\n",
      "result: Catherine Parr, answer: Catherine Parr\n",
      "result: Natural resource, answer: Natural resource\n",
      "result: Mary Shelley, answer: Mary Shelley\n",
      "result: Māori, answer: Māori\n",
      "result: Tamil Nadu, answer: Tamil Nadu\n",
      "result: Republic of Mahabad, answer: Hadschi Baba Scheich\n",
      "result: 1590s, answer: Diego Velázquez\n",
      "result: Aquamarine, answer: Deep house\n",
      "result: President of the United States, answer: 1767\n",
      "result: Shania Twain, answer: Shania Twain\n",
      "result: Paradox, answer: Paradox\n",
      "result: Calabria, answer: 1005\n",
      "result: Yes, answer: Finnish language\n",
      "result: Hyves, answer: Hyves\n",
      "result: Cairo, answer: Cairo\n",
      "result: Subtraction, answer: Complex number\n",
      "result: Indonesia, answer: Java\n",
      "result: Boiling point, answer: Boil\n",
      "result: Guernsey, answer: Bailiwick of Guernsey\n",
      "result: Eurasia, answer: Eurasian people\n",
      "result: Smashing Pumpkins, answer: Smashing Pumpkins\n",
      "result: Jharkhand, answer: Jharkhand\n",
      "result: Rabies, answer: Rabies\n",
      "result: Spider-Man, answer: Spider-Man\n",
      "result: Singapore, answer: Independence\n",
      "result: James A. Garfield, answer: James A. Garfield\n",
      "result: Bill Cosby, answer: Bill Cosby\n",
      "result: Family, answer: Family\n",
      "result: Brighton, answer: Brighton\n",
      "result: Saturated fat, answer: Saturated fat\n",
      "result: Patent, answer: Patent\n",
      "result: Density, answer: Liquid\n",
      "result: Stone Age, answer: Stone Age\n",
      "result: Cellulose, answer: Cellulose\n",
      "result: Standard Model, answer: Gluon\n",
      "result: Sega, answer: Doom\n",
      "result: Belgium, answer: 1252\n",
      "result: Diarrhea, answer: Diarrhea\n",
      "result: Mars, answer: Erebos\n",
      "result: History of Australia, answer: Dreamtime\n",
      "result: Netherlands, answer: Eighty Years' War\n",
      "result: Dachshund, answer: Dachshund\n",
      "result: Director, answer: Director\n",
      "result: Essen, answer: Essen\n",
      "result: Centimetre, answer: Centimetre\n",
      "result: Game Boy line, answer: Video game console\n",
      "result: Grammy Award, answer: Tommy Roe\n",
      "result: Espoo, answer: Tuupovaara\n",
      "result: Dream Theater, answer: Dream Theater\n",
      "result: Great Wall of China, answer: Great Wall of China\n",
      "result: Katharine Hepburn, answer: January 6\n",
      "result: Counter-Reformation, answer: Catholic Church\n",
      "result: Resurrection, answer: Thomas the Apostle\n",
      "result: Telemachus, answer: 404\n",
      "result: Paul Anka, answer: Paul Anka\n",
      "result: Electronic Entertainment Expo, answer: Electronic Entertainment Expo\n",
      "result: M6 motorway, answer: M6 motorway\n",
      "result: Nerve agent, answer: Nerve agent\n",
      "result: Appellation d'origine contrôlée, answer: Calvados (drink)\n",
      "result: Charles Dickens, answer: 1819\n",
      "result: Central America, answer: Central America\n",
      "result: Anthropomorphism, answer: Space Runaway Ideon\n",
      "result: Military–industrial complex, answer: Military–industrial complex\n",
      "result: Emperor of Ethiopia, answer: 1667\n",
      "result: Theme park, answer: Anaheim, California\n",
      "result: Dante Alighieri, answer: 1265\n",
      "result: Diogenes of Sinope, answer: 10\n",
      "result: Martin Luther, answer: Protestantism\n",
      "result: 1859, answer: 1859\n",
      "result: Odd number, answer: Even number\n",
      "result: Las Vegas, answer: Las Vegas\n",
      "result: Corinth, answer: Isthmus of Corinth\n",
      "result: Brand, answer: Brand\n",
      "result: Sino-Japanese War, answer: 1895\n",
      "result: Royal Opera House, answer: 1735\n",
      "result: Andorra, answer: Andorra\n",
      "result: Rainbow, answer: Rainbow flag\n",
      "result: Kilogram, answer: Temperature\n",
      "result: City, answer: New town\n",
      "result: Typewriter, answer: Rudolf Diesel\n",
      "result: Ostrich, answer: Eagle\n",
      "result: Computer multitasking, answer: Multitasking\n",
      "result: Winston Churchill, answer: Winston Churchill\n",
      "result: Lisa Kudrow, answer: Lisa Kudrow\n",
      "result: Baby, answer: Sentence\n",
      "result: China, answer: People's Republic of China\n",
      "result: Andrew Jackson, answer: 1833\n",
      "result: Ted Bundy, answer: Hostage\n",
      "result: Mediterranean Sea, answer: Mediterranean Sea\n",
      "result: Stephen of England, answer: 1153\n",
      "result: United Nations General Assembly, answer: United Nations General Assembly\n",
      "result: San Marino, answer: San Marino\n",
      "result: Nupedia, answer: Nupedia\n",
      "result: Moers, answer: Moers\n",
      "result: Mammal, answer: Egg (biology)\n",
      "result: John le Carré, answer: John le Carré\n",
      "result: Giro d'Italia, answer: Giro d'Italia\n",
      "result: Colombia, answer: Colombia\n",
      "result: 1976, answer: February 3\n",
      "result: England, answer: August 10\n",
      "result: Wrench, answer: Wrench\n",
      "result: George Gershwin, answer: George Gershwin\n",
      "result: Chile, answer: Aymara language\n",
      "result: Probability, answer: Probability\n",
      "result: Katharine Hepburn, answer: June 16\n",
      "result: Indo-European languages, answer: Telugu\n",
      "result: Suburb, answer: Suburb\n",
      "result: The Alamo, answer: Still\n",
      "result: Mona Lisa, answer: 1500s\n",
      "result: Larry David, answer: Country music\n",
      "result: Star, answer: Nuclear fusion\n",
      "result: Green, answer: Green\n",
      "result: Imagination, answer: Imagination\n",
      "result: Mao Zedong, answer: Mao Zedong\n",
      "result: 1185, answer: 1581\n",
      "result: Business, answer: Business\n",
      "result: Web browser, answer: Mozilla Firefox\n",
      "result: Starbucks, answer: Starbucks\n",
      "result: 30s BC, answer: Mark Antony\n",
      "result: Moctezuma II, answer: Moctezuma II\n",
      "result: Demographics of Nicaragua, answer: Demographics of Nicaragua\n",
      "result: Sydney, answer: 1788\n",
      "result: Béla Bartók, answer: Béla Bartók\n",
      "result: Holy Roman Emperor, answer: May 6\n",
      "result: Utah, answer: 1896\n",
      "result: Board game, answer: Board game\n",
      "result: Constantine the Great, answer: September 12\n",
      "result: Sexual orientation, answer: Sexual orientation\n",
      "result: South Dakota, answer: Rapid City, South Dakota\n",
      "result: George H. W. Bush, answer: 1773\n",
      "result: Domestication, answer: Pork\n",
      "result: Saturn, answer: 1655\n",
      "result: 1488, answer: 1583\n",
      "result: Toyota, answer: Toyota\n",
      "result: Internet Relay Chat, answer: Internet Relay Chat\n",
      "result: Viktor Yanukovych, answer: Viktor Yanukovych\n",
      "result: Metallica, answer: Metallica\n",
      "result: Freddie Mercury, answer: Freddie Mercury\n",
      "result: 1056, answer: 1056\n",
      "result: Ferret, answer: Ferret\n",
      "result: First aid, answer: Drunkenness\n",
      "result: Cherry, answer: Cherry\n",
      "result: April, answer: Drizzle\n",
      "result: Currency, answer: Rupee\n",
      "result: Zebra, answer: Zebra\n",
      "result: Trilogy, answer: The Godfather\n",
      "result: Proof, answer: Proof\n",
      "result: Brunei, answer: May 28\n",
      "result: Panama, answer: Panama\n",
      "result: 1714, answer: June 26\n",
      "result: Middle Ages, answer: Scandinavia\n",
      "result: Hydroelectricity, answer: Hydroelectricity\n",
      "result: Robert E. Lee, answer: 1862\n",
      "result: Erwin Rommel, answer: Erwin Rommel\n",
      "result: Leaf, answer: Branch\n",
      "result: Cone, answer: Cone\n",
      "result: Helium, answer: Helium\n",
      "result: Article, answer: Article (grammar)\n",
      "result: Aphex Twin, answer: Aphex Twin\n",
      "result: Stephen of England, answer: Anarchy\n",
      "result: Hart Memorial Trophy, answer: Hart Memorial Trophy\n",
      "result: Salami, answer: Salami\n",
      "result: Country, answer: Sealand\n",
      "result: Trumpet, answer: Eddie Condon\n",
      "result: Echidna, answer: Monotreme\n",
      "result: Westlife, answer: Westlife\n",
      "result: Starch, answer: Amylase\n",
      "result: Pain, answer: Dental floss\n",
      "result: County town, answer: County town\n",
      "result: Death penalty, answer: Death penalty\n",
      "result: Farscape, answer: Avatar (disambiguation)\n",
      "result: Eastbourne, answer: Eastbourne\n",
      "result: Scottish Football League, answer: Glasgow\n",
      "result: Peekskill, New York, answer: Peekskill, New York\n",
      "result: Formula 1, answer: Austin, Texas\n",
      "result: Terry Bradshaw, answer: January 27\n",
      "result: Pipette, answer: Beaker\n",
      "result: Cloud, answer: Cloud\n",
      "result: Natural resource, answer: Natural resource\n",
      "result: Sword, answer: Sword\n",
      "result: Kingman Reef, answer: Kingman Reef\n",
      "result: Niihau, answer: Niihau\n",
      "result: Massachusetts, answer: Brockton, Massachusetts\n",
      "result: Indonesia, answer: List of volcanoes\n",
      "Our model scored 14782/31274 points on the training set.\n"
     ]
    }
   ],
   "source": [
    "# Test the performance of our new model\n",
    "score = 0\n",
    "totalScore = 0\n",
    "\n",
    "for set in train[:500]:\n",
    "    query = set['question']\n",
    "    query_vector = generate_embeddings(query)\n",
    "    result = search_and_query(collection, [query_vector], \"embeddings\", {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}, set['points'], set['question'])\n",
    "    print(f\"result: {result}, answer: {set['article']}\")\n",
    "    if result.lower() in set['article'].lower():\n",
    "        score += set['points']\n",
    "    totalScore += set['points']\n",
    "\n",
    "print(f\"Our model scored {score}/{totalScore} points on the training set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model scored 14782/31274 points on the training set.\n",
    "# Whoops, it's slightly worse than before. Let's stick with the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to the old model\n",
    "\n",
    "def search_and_query(collection, search_vectors, search_field, search_params):\n",
    "    collection.load()\n",
    "    result = collection.search(search_vectors, search_field, search_params, limit=3, output_fields=[\"title\"])\n",
    "    return result[0][0].entity.get(\"title\")\n",
    "\n",
    "# Read the test set\n",
    "\n",
    "test = []\n",
    "with open(\"test.jsonl\", \"r\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        test.append(json.loads(line))\n",
    "\n",
    "print(test[0]['question'], test[0]['points'])\n",
    "print(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07a85a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate results for the test set\n",
    "for set in test:\n",
    "    query = set['question']\n",
    "    query_vector = generate_embeddings(query)\n",
    "    result = search_and_query(collection, [query_vector], \"embeddings\", {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}})\n",
    "    set['answer'] = result\n",
    "\n",
    "    with open(\"submission.jsonl\", \"a\", encoding='utf-8') as f:\n",
    "        f.write(f\"{set}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f08527",
   "metadata": {},
   "source": [
    "# Your algorithm choice\n",
    "I used a vector database to store the embeddings of each article with a label of the article title. I then generated embeddings of each question and did a vector similarity search to find the most similar articles.\n",
    "\n",
    "# How you would extend this algorithm to 100k/1m/1b articles\n",
    "This method should still be workable for 100k articles, but the database might be too large for 1m/1b articles. I investigated the proportion of nouns at the start because I thought it may be a good idea to do a breadth-first search by looking up the articles for all the nouns in the question, and then looking for the answer in these articles. If those articles don't contain a satisfactory answer, we could then extract the nouns from these articles and search until we find an answer. For the small size of data I was provided this wasn't necessary, this method could work to ensure that only a small number of articles are added to the vector database and we don't run out of space/time.\n",
    "\n",
    "# Evaluating performance\n",
    "Since I didn't have to do training, the entire train dataset acted as my train dataset. \n",
    "I don't have much experience working with docker and my Milvus container kept stopping on its own (possibly due to memory issues as I'm running this on my laptop). Because of this, I had to limit the sample size to the first 500 entries but I think this still gave a pretty good evaluation of model performance especially as I was comparing the version which weighted based on points.\n",
    "\n",
    "# Any reference that you found interesting\n",
    "I've worked with vector databases before with Pinecone but it was my first time setting it up and running it on my laptop with Milvus. It was a good learning process!\n",
    "\n",
    "# Ideas that worked / did not work \n",
    "As discussed, open source language embedding models are advanced enough to make my more primitive methods relying on NLP to be obsolete at this scale.\n",
    "\n",
    "I was surprised my trick of using the points to observe whether the answer is in the title caused the performance to drop so drastically, but this could be because the relationship between points and the answer being in the question wasn't strong in the first place. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
